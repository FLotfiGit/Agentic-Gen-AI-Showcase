"""Generation utilities: LLM wrapper, prompt templates, and safe sampling defaults.

Lightweight wrapper: tries OpenAI ChatCompletion if `OPENAI_API_KEY` is set, otherwise uses a deterministic stub.
"""
import os
from typing import Dict, Any


def stub_generate(prompt: str, max_tokens: int = 64, temperature: float = 0.0) -> str:
    # Deterministic stub for tests/demos
    if "summarize" in prompt.lower():
        return "Summary: This is a short, deterministic summary generated by the stub."
    if "caption" in prompt.lower() or "describe" in prompt.lower():
        return "A vivid, short caption generated by stub: a person interacting with an AI interface."
    return "Generated text (stub): " + (prompt[:140].replace('\n',' '))


def openai_generate(prompt: str, max_tokens: int = 150, temperature: float = 0.2) -> str:
    try:
        import openai
    except Exception as e:
        raise RuntimeError("openai package not installed") from e
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        raise RuntimeError("OPENAI_API_KEY not set")
    openai.api_key = key
    resp = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=temperature,
    )
    return resp.choices[0].message.content


def generate_text(prompt: str, max_tokens: int = 150, temperature: float = 0.2) -> str:
    """Generate text using OpenAI when available, otherwise the stub.

    Returns the generated string.
    """
    try:
        if os.getenv("OPENAI_API_KEY"):
            return openai_generate(prompt, max_tokens=max_tokens, temperature=temperature)
    except Exception:
        # fall back to stub if OpenAI fails
        pass
    return stub_generate(prompt, max_tokens=max_tokens, temperature=temperature)


def caption_prompt_from_image_embedding(embedding_vector) -> str:
    """Create a small prompt that asks the LLM for a caption given an image embedding.

    For now the embedding is not directly consumed by the LLM (would require a multimodal model).
    We include the embedding norm and size as context to help the stub produce different outputs.
    """
    norm = float(sum(float(x) * float(x) for x in embedding_vector) ** 0.5)
    return f"Describe the following image in one short sentence. Embedding-norm={norm:.3f}, dim={len(embedding_vector)}."
